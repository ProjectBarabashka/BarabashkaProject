import subprocess
import ollama
import requests

# –ù–ê–°–¢–†–û–ô–ö–ò PROJECT BARABASHKA
TOKEN = "8499286144:AAED49Ma-V6CogW8PEa0evpBdEqt6poZNLc"
CHAT_ID = "747673564"

def send_tg(text):
    try:
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –î–æ–±–∞–≤–ª–µ–Ω /bot –ø–µ—Ä–µ–¥ —Ç–æ–∫–µ–Ω–æ–º
        url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
        params = {"chat_id": CHAT_ID, "text": text}
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –î–æ–±–∞–≤–ª–µ–Ω —Ä–µ–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ —Å–µ—Ä–≤–µ—Ä—É
        response = requests.get(url, params=params)
        return response.json()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}")

# 1. –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—ã
try:
    gpu_raw = subprocess.getoutput('nvidia-smi --query-gpu=temperature.gpu,utilization.gpu,memory.used --format=csv,noheader,nounits')
except Exception as e:
    gpu_raw = "–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö GPU"

# 2. –û–ø—Ä–∞—à–∏–≤–∞–µ–º Llama 3
prompt = f"""
–¢—ã ‚Äî –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥-—Å–∏—Å—Ç–µ–º–∞ ProjectBarabashka. 
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—ã, –∫–æ—Ç–æ—Ä—É—é –º—ã —Å–¥–∞–µ–º –≤ –∞—Ä–µ–Ω–¥—É –Ω–∞ Clore.ai.
–î–∞–Ω–Ω—ã–µ (–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞, –ù–∞–≥—Ä—É–∑–∫–∞ %, –ü–∞–º—è—Ç—å MB): {gpu_raw}

–ï—Å–ª–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ > 80 –∏–ª–∏ –ù–∞–≥—Ä—É–∑–∫–∞ 100% –¥–æ–ª–≥–æ, –Ω–∞–ø–∏—à–∏ –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º.
–ï—Å–ª–∏ –≤—Å—ë –≤ –Ω–æ—Ä–º–µ, –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ "–°—Ç–∞—Ç—É—Å: –°—Ç–∞–±–∏–ª—å–Ω–æ" –∏ –∫—Ä–∞—Ç–∫–æ —Ü–∏—Ñ—Ä—ã.
–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
"""

try:
    response = ollama.generate(model='llama3', prompt=prompt)
    analysis = response['response'].strip()
    
    # 3. –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç—á–µ—Ç–∞ –≤ Telegram
    send_tg(f"üìä [ProjectBarabashka Clore Report]\n\n{analysis}")
    print(f"–û—Ç—á–µ—Ç —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {analysis}")
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ Ollama: {e}")
