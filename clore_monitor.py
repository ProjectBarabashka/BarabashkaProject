import subprocess
import ollama
import requests

# –ù–ê–°–¢–†–û–ô–ö–ò PROJECT BARABASHKA
TOKEN = "8499286144:AAED49Ma-V6CogW8PEa0evpBdEqt6poZNLc"
CHAT_ID = "747673564"

def send_tg(text):
    try:
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –¥–æ–±–∞–≤–ª–µ–Ω /bot –ø–µ—Ä–µ–¥ TOKEN
        url = f"https://api.telegram.org{TOKEN}/sendMessage"
        params = {"chat_id": CHAT_ID, "text": text}
        r = requests.get(url, params=params, timeout=15)
        if r.status_code == 200:
            print("‚úÖ –°–æ–æ–±—â–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ —É–ª–µ—Ç–µ–ª–æ –≤ Telegram!")
        else:
            # –≠—Ç–æ –ø–æ–º–æ–∂–µ—Ç —É–≤–∏–¥–µ—Ç—å –æ—à–∏–±–∫—É, –µ—Å–ª–∏ ID —á–∞—Ç–∞ –Ω–µ–≤–µ—Ä–Ω—ã–π
            print(f"‚ùå –û—à–∏–±–∫–∞ Telegram: {r.status_code} - {r.text}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}")

# 1. –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –∫–∞—Ä—Ç—ã
gpu_raw = subprocess.getoutput('nvidia-smi --query-gpu=temperature.gpu,utilization.gpu,memory.used --format=csv,noheader,nounits')

# 2. –û–ø—Ä–∞—à–∏–≤–∞–µ–º Llama 3
prompt = f"""
–¢—ã ‚Äî –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥-—Å–∏—Å—Ç–µ–º–∞ ProjectBarabashka. 
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—ã –Ω–∞ Clore.ai.
–î–∞–Ω–Ω—ã–µ (–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞, –ù–∞–≥—Ä—É–∑–∫–∞ %, –ü–∞–º—è—Ç—å MB): {gpu_raw}

–ï—Å–ª–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ > 80 –∏–ª–∏ –ù–∞–≥—Ä—É–∑–∫–∞ 100% –¥–æ–ª–≥–æ, –Ω–∞–ø–∏—à–∏ –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º.
–ï—Å–ª–∏ –≤—Å—ë –≤ –Ω–æ—Ä–º–µ, –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ "–°—Ç–∞—Ç—É—Å: –°—Ç–∞–±–∏–ª—å–Ω–æ" –∏ –∫—Ä–∞—Ç–∫–æ —Ü–∏—Ñ—Ä—ã.
–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
"""

try:
    print("‚è≥ –õ–∞–º–∞ –¥—É–º–∞–µ—Ç...")
    response = ollama.generate(model='llama3', prompt=prompt)
    analysis = response['response'].strip()
    
    # 3. –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram
    send_tg(f"üìä [ProjectBarabashka Clore Report]\n\n{analysis}")
    print(f"–û—Ç—á–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {analysis}")
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ Ollama: {e}")
